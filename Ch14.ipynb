{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch14ï¼š Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RNNs in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt](./14_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "n_inputs=3\n",
    "n_neurons=5\n",
    "\n",
    "X0=tf.placeholder(tf.float32,[None,n_inputs])\n",
    "X1=tf.placeholder(tf.float32,[None,n_inputs])\n",
    "\n",
    "Wx=tf.Variable(tf.random_normal(shape=[n_inputs,n_neurons],dtype=tf.float32))\n",
    "Wy=tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons],dtype=tf.float32))\n",
    "b=tf.Variable(tf.zeros([1,n_neurons],dtype=tf.float32))\n",
    "\n",
    "Y0=tf.tanh(tf.matmul(X0,Wx)+b)\n",
    "Y1=tf.tanh(tf.matmul(Y0,Wy)+tf.matmul(X1,Wx)+b)\n",
    "\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X0_batch=np.array([[0,1,2],[3,4,5],[6,7,8],[9,0,1]])\n",
    "X1_batch=np.array([[9,8,7],[0,0,0],[6,5,4],[3,2,1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val,Y1_val=sess.run([Y0,Y1],feed_dict={X0:X0_batch,X1:X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17640039 -0.57224655 -0.99719042 -0.16053186  0.99741298]\n",
      " [ 0.38764769 -0.99663621 -1.          0.99994576  0.99994975]\n",
      " [ 0.76004553 -0.9999792  -1.          1.          0.99999905]\n",
      " [-0.96280271 -0.99324793 -1.          1.         -0.99999988]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.88383186 -0.99999994 -1.          1.          0.66440773]\n",
      " [ 0.28166419 -0.939812    0.63064516  0.99659473 -0.9927938 ]\n",
      " [ 0.94650102 -0.99997854 -1.          1.         -0.99412483]\n",
      " [-0.91097897 -0.99999619 -0.9999994   0.99999797  0.28794128]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Unrolling Through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X0=tf.placeholder(tf.float32,[None,n_inputs])\n",
    "X1=tf.placeholder(tf.float32,[None,n_inputs])\n",
    "\n",
    "basic_cell=tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs,states=tf.contrib.rnn.static_rnn(basic_cell,[X0,X1],dtype=tf.float32)\n",
    "\n",
    "Y0,Y1=output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val_s,Y1_val_s=sess.run([Y0,Y1],feed_dict={X0:X0_batch,X1:X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21036781  0.62269402 -0.73273349 -0.57639426 -0.66842997]\n",
      " [-0.92657721  0.97495639 -0.99965382 -0.76476115 -0.75942796]\n",
      " [-0.99555725  0.99861777 -0.99999964 -0.87595707 -0.82802624]\n",
      " [-0.99854875  0.99938279 -0.99822694  0.881194    0.99997175]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_steps=2\n",
    "X=tf.placeholder(tf.float32,[None,n_steps,n_inputs])\n",
    "X_seqs=tf.unstack(tf.transpose(X,perm=[1,0,2]))\n",
    "basic_cell=tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs,states=tf.contrib.rnn.static_rnn(basic_cell,X_seqs,dtype=tf.float32)\n",
    "outputs=tf.transpose(tf.stack(output_seqs),perm=[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch=np.array([\n",
    "    [[0,1,2],[9,8,7]],\n",
    "    [[3,4,5],[0,0,0]],\n",
    "    [[6,7,8],[6,5,4]],\n",
    "    [[9,0,1],[3,2,1]],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val=outputs.eval(feed_dict={X:X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.859366    0.58419371  0.83167094  0.773076   -0.15731491]\n",
      "  [ 0.98212183  0.99998742  0.44587341 -0.98545146 -0.99919242]]\n",
      "\n",
      " [[ 0.97351664  0.99526483  0.97424823  0.60056984 -0.9511109 ]\n",
      "  [ 0.91413325 -0.03092584 -0.96910113 -0.00953994  0.89254838]]\n",
      "\n",
      " [[ 0.99524945  0.99995703  0.99630409  0.34534392 -0.99827683]\n",
      "  [ 0.95794982  0.99945277 -0.87225997 -0.9305886  -0.95641518]]\n",
      "\n",
      " [[-0.999798    0.99999243 -0.99960452 -0.99842173 -0.96516532]\n",
      "  [-0.4336051   0.98613524 -0.35819459  0.08651786 -0.94640535]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynmaic Unrolling Through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X=tf.placeholder(tf.float32,[None,n_steps,n_inputs])\n",
    "basic_cell=tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs,states=tf.nn.dynamic_rnn(basic_cell,X,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Variable Length Input Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "seq_length=tf.placeholder(tf.int32,[None])\n",
    "n_setps=2\n",
    "X=tf.placeholder(tf.float32,[None,n_steps,n_inputs])\n",
    "X_seqs=tf.unstack(tf.transpose(X,perm=[1,0,2]))\n",
    "basic_cell=tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs,states=tf.nn.dynamic_rnn(basic_cell,X,dtype=tf.float32,sequence_length=seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch=np.array([\n",
    "    [[0,1,2],[9,8,7]],\n",
    "    [[3,4,5],[0,0,0]],\n",
    "    [[6,7,8],[6,5,4]],\n",
    "    [[9,0,1],[3,2,1]]\n",
    "])\n",
    "seq_length_batch=np.array([2,1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val,states_val=sess.run([outputs,states],feed_dict={X:X_batch,seq_length:seq_length_batch})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.12516126  0.63551056  0.59586692  0.53054917  0.23055492]\n",
      "  [-0.99999934 -0.77043694  0.99999851  0.9973703  -0.98947817]]\n",
      "\n",
      " [[-0.98314834  0.673204    0.99586034  0.96472472 -0.42871615]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.99988776  0.70769632  0.99996614  0.99790025 -0.81822425]\n",
      "  [-0.99972206 -0.54172385  0.99976474  0.97281468 -0.9927848 ]]\n",
      "\n",
      " [[-0.99995035 -0.91577137  0.99969298 -0.0180788  -0.96920443]\n",
      "  [-0.92923605  0.20204246  0.89805973  0.68673497 -0.93606234]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99999934 -0.77043694  0.99999851  0.9973703  -0.98947817]\n",
      " [-0.98314834  0.673204    0.99586034  0.96472472 -0.42871615]\n",
      " [-0.99972206 -0.54172385  0.99976474  0.97281468 -0.9927848 ]\n",
      " [-0.92923605  0.20204246  0.89805973  0.68673497 -0.93606234]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Variable-Length Output Sequence\n",
    "Nothing to code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "n_steps=28\n",
    "n_inputs=28\n",
    "n_neurons=150\n",
    "n_outputs=10\n",
    "\n",
    "learning_rate=0.001\n",
    "\n",
    "X=tf.placeholder(tf.float32,[None,n_steps,n_inputs])\n",
    "y=tf.placeholder(tf.int32,[None])\n",
    "\n",
    "basic_cell=tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs,states=tf.nn.dynamic_rnn(basic_cell,X,dtype=tf.float32)\n",
    "\n",
    "logits=fully_connected(states,n_outputs,activation_fn=None)\n",
    "xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss=tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op=optimizer.minimize(loss)\n",
    "correct=tf.nn.in_top_k(logits,y,1)\n",
    "accuracy=tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist=input_data.read_data_sets(\"/tmp/data\")\n",
    "X_test=mnist.test.images.reshape(-1,n_steps,n_inputs)\n",
    "y_test=mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Training accuracy: 0.92 Test accuracy: 0.9184\n",
      "1 Training accuracy: 0.966667 Test accuracy: 0.9492\n",
      "2 Training accuracy: 0.94 Test accuracy: 0.9496\n",
      "3 Training accuracy: 0.966667 Test accuracy: 0.961\n",
      "4 Training accuracy: 0.973333 Test accuracy: 0.9709\n",
      "5 Training accuracy: 0.973333 Test accuracy: 0.9712\n",
      "6 Training accuracy: 0.96 Test accuracy: 0.9639\n",
      "7 Training accuracy: 0.993333 Test accuracy: 0.9709\n",
      "8 Training accuracy: 0.966667 Test accuracy: 0.9656\n",
      "9 Training accuracy: 0.993333 Test accuracy: 0.9683\n",
      "10 Training accuracy: 0.98 Test accuracy: 0.967\n",
      "11 Training accuracy: 0.966667 Test accuracy: 0.9771\n",
      "12 Training accuracy: 1.0 Test accuracy: 0.9737\n",
      "13 Training accuracy: 0.973333 Test accuracy: 0.9721\n",
      "14 Training accuracy: 0.966667 Test accuracy: 0.9738\n",
      "15 Training accuracy: 0.98 Test accuracy: 0.9726\n",
      "16 Training accuracy: 0.986667 Test accuracy: 0.9761\n",
      "17 Training accuracy: 0.986667 Test accuracy: 0.9753\n",
      "18 Training accuracy: 0.98 Test accuracy: 0.9719\n",
      "19 Training accuracy: 1.0 Test accuracy: 0.978\n",
      "20 Training accuracy: 1.0 Test accuracy: 0.9749\n",
      "21 Training accuracy: 0.986667 Test accuracy: 0.9732\n",
      "22 Training accuracy: 0.98 Test accuracy: 0.9754\n",
      "23 Training accuracy: 1.0 Test accuracy: 0.9772\n",
      "24 Training accuracy: 1.0 Test accuracy: 0.9731\n",
      "25 Training accuracy: 0.993333 Test accuracy: 0.978\n",
      "26 Training accuracy: 0.973333 Test accuracy: 0.9761\n",
      "27 Training accuracy: 0.993333 Test accuracy: 0.9758\n",
      "28 Training accuracy: 0.986667 Test accuracy: 0.9752\n",
      "29 Training accuracy: 1.0 Test accuracy: 0.9801\n",
      "30 Training accuracy: 0.993333 Test accuracy: 0.9747\n",
      "31 Training accuracy: 0.993333 Test accuracy: 0.9753\n",
      "32 Training accuracy: 0.986667 Test accuracy: 0.9769\n",
      "33 Training accuracy: 0.993333 Test accuracy: 0.975\n",
      "34 Training accuracy: 1.0 Test accuracy: 0.9788\n",
      "35 Training accuracy: 0.993333 Test accuracy: 0.9794\n",
      "36 Training accuracy: 0.993333 Test accuracy: 0.9802\n",
      "37 Training accuracy: 1.0 Test accuracy: 0.9774\n",
      "38 Training accuracy: 0.993333 Test accuracy: 0.9784\n",
      "39 Training accuracy: 0.993333 Test accuracy: 0.9808\n",
      "40 Training accuracy: 0.993333 Test accuracy: 0.9735\n",
      "41 Training accuracy: 0.993333 Test accuracy: 0.977\n",
      "42 Training accuracy: 1.0 Test accuracy: 0.9766\n",
      "43 Training accuracy: 0.993333 Test accuracy: 0.9792\n",
      "44 Training accuracy: 0.993333 Test accuracy: 0.9788\n",
      "45 Training accuracy: 0.986667 Test accuracy: 0.9709\n",
      "46 Training accuracy: 0.993333 Test accuracy: 0.9742\n",
      "47 Training accuracy: 0.986667 Test accuracy: 0.9782\n",
      "48 Training accuracy: 1.0 Test accuracy: 0.9779\n",
      "49 Training accuracy: 1.0 Test accuracy: 0.9771\n",
      "50 Training accuracy: 0.993333 Test accuracy: 0.9769\n",
      "51 Training accuracy: 1.0 Test accuracy: 0.979\n",
      "52 Training accuracy: 0.993333 Test accuracy: 0.9769\n",
      "53 Training accuracy: 0.986667 Test accuracy: 0.9797\n",
      "54 Training accuracy: 0.986667 Test accuracy: 0.9729\n",
      "55 Training accuracy: 0.993333 Test accuracy: 0.9796\n",
      "56 Training accuracy: 0.986667 Test accuracy: 0.9768\n",
      "57 Training accuracy: 0.986667 Test accuracy: 0.9789\n",
      "58 Training accuracy: 1.0 Test accuracy: 0.9737\n",
      "59 Training accuracy: 0.993333 Test accuracy: 0.9751\n",
      "60 Training accuracy: 0.986667 Test accuracy: 0.9779\n",
      "61 Training accuracy: 1.0 Test accuracy: 0.9779\n",
      "62 Training accuracy: 0.993333 Test accuracy: 0.9776\n",
      "63 Training accuracy: 1.0 Test accuracy: 0.9811\n",
      "64 Training accuracy: 0.993333 Test accuracy: 0.9786\n",
      "65 Training accuracy: 1.0 Test accuracy: 0.9748\n",
      "66 Training accuracy: 1.0 Test accuracy: 0.9745\n",
      "67 Training accuracy: 0.98 Test accuracy: 0.9766\n",
      "68 Training accuracy: 0.993333 Test accuracy: 0.9771\n",
      "69 Training accuracy: 1.0 Test accuracy: 0.9792\n",
      "70 Training accuracy: 1.0 Test accuracy: 0.9764\n",
      "71 Training accuracy: 1.0 Test accuracy: 0.9772\n",
      "72 Training accuracy: 1.0 Test accuracy: 0.9791\n",
      "73 Training accuracy: 0.993333 Test accuracy: 0.9764\n",
      "74 Training accuracy: 0.98 Test accuracy: 0.9786\n",
      "75 Training accuracy: 1.0 Test accuracy: 0.9718\n",
      "76 Training accuracy: 0.993333 Test accuracy: 0.9768\n",
      "77 Training accuracy: 1.0 Test accuracy: 0.9795\n",
      "78 Training accuracy: 0.986667 Test accuracy: 0.9722\n",
      "79 Training accuracy: 0.993333 Test accuracy: 0.9796\n",
      "80 Training accuracy: 0.993333 Test accuracy: 0.9794\n",
      "81 Training accuracy: 1.0 Test accuracy: 0.9749\n",
      "82 Training accuracy: 1.0 Test accuracy: 0.9777\n",
      "83 Training accuracy: 1.0 Test accuracy: 0.9773\n",
      "84 Training accuracy: 0.973333 Test accuracy: 0.9762\n",
      "85 Training accuracy: 0.993333 Test accuracy: 0.9777\n",
      "86 Training accuracy: 0.993333 Test accuracy: 0.9729\n",
      "87 Training accuracy: 1.0 Test accuracy: 0.9737\n",
      "88 Training accuracy: 0.993333 Test accuracy: 0.9783\n",
      "89 Training accuracy: 0.986667 Test accuracy: 0.9766\n",
      "90 Training accuracy: 0.986667 Test accuracy: 0.9718\n",
      "91 Training accuracy: 0.986667 Test accuracy: 0.9735\n",
      "92 Training accuracy: 0.993333 Test accuracy: 0.9783\n",
      "93 Training accuracy: 1.0 Test accuracy: 0.9797\n",
      "94 Training accuracy: 0.993333 Test accuracy: 0.9809\n",
      "95 Training accuracy: 0.986667 Test accuracy: 0.9751\n",
      "96 Training accuracy: 0.98 Test accuracy: 0.9757\n",
      "97 Training accuracy: 1.0 Test accuracy: 0.9786\n",
      "98 Training accuracy: 0.98 Test accuracy: 0.9763\n",
      "99 Training accuracy: 1.0 Test accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "n_epochs=100\n",
    "batch_size=150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples//batch_size):\n",
    "            X_batch,y_batch=mnist.train.next_batch(batch_size)\n",
    "            X_batch=X_batch.reshape(-1,n_steps,n_inputs)\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "        acc_train=accuracy.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "        acc_test=accuracy.eval(feed_dict={X:X_test,y:y_test})\n",
    "        print(epoch,\"Training accuracy:\",acc_train,\"Test accuracy:\",acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
